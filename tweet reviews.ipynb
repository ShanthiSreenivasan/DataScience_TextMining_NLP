{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd() # Print current working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to read a single text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MyTextFile1.txt','r') as f:\n",
    "    for line in f:\n",
    "        print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read multiple text files as a dataframe in python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'C:\\\\Users\\\\'\n",
    "os.chdir(loc)\n",
    "filelist = os.listdir()  # Listing all the file names present at this location \n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []  # Defining an empty list \n",
    "path = loc\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(f)]\n",
    "for f in files:\n",
    "    with open(f,'r') as myfile:  # Opening the file\n",
    "        data.append(myfile.read())  # Reading and appending the content of that file in list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  \n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)  # List is getting converted in the dataframe \n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  # Sitting in memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all the files from the LAN \n",
    "# and classify files in five classes \n",
    "# Finance \n",
    "# HR \n",
    "# Engineering \n",
    "# Sales \n",
    "# Professional services "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read a large csv files \n",
    "# Steps \n",
    "# Use chunksize option \n",
    "# DF1 = 1st 10k \n",
    "# DF2 = 2nd 10k \n",
    "# DFn = last 10k \n",
    "# appending these chunks in final Dataframe \n",
    "# DF1 = pd.read_csv( \"filename.csv\", chunksize = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read twitter data in python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps \n",
    "# Appropriate library \n",
    "# On the developer site of twitter you need to register a dummy application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the libraries\n",
    "import tweepy, codecs\n",
    "\n",
    "# https://apps.twitter.com/app/6270442/show\n",
    "\n",
    "## fill in your Twitter credentials \n",
    "consumer_key = \"J4wbIOkVMhfnldyYJk9Ml1xBI\"\n",
    "consumer_secret = \"XsZVbiJc8VDFQaI2JwfhWEpaSQcDWpYPJ6miA3KegusJ8MPe0d\"\n",
    "access_token = \"1050635730-zKs23r1LdGF75CgAsRlfMtOmrZT4pKqvLMgyGnC\"\n",
    "access_token_secret = \"l9zYaR1nZmaklXAZNlB3FKX5hPSNpIYPDeExay8KHzCjF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let Tweepy set up an instance of the REST API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# successful execution of this command means that a connection is established between twitter and python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in your search query and store your results in a variable\n",
    "results = api.search(q = \"Umer Sharif\", lang = \"en\", result_type = \"recent\", count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "\n",
    "# How to convert this result into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.home_timeline(\"@NarendraModi\")  # Tweets that are originating from this handle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is trending in India ( WOEID of India)\n",
    "#api.trends_place(\"23424848\")\n",
    "# 20070458\n",
    "api.trends_place(\"2459115\")\n",
    "\n",
    "# Hashtag those are trending in India "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "## use the codecs library to write the text of the Tweets to a .txt file\n",
    "file = codecs.open(\"My_file.txt\", \"w\", \"utf-8\")\n",
    "for result in results:\n",
    "    file.write(result.text)\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_table(\"C:\\\\Users\\\\anparash\\\\MyTextFlieFolder\\\\My_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression ( RegEx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to find or replace of particular pattern inside a string with a minimal amount of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case:- \n",
    "# 1 - Write down a RegEx to validate an email address \n",
    "# 2 - ...................  to validare a website \n",
    "# 3-  validate a PAN card or Aadhar or SSN or Phone number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library re- Regular Expression \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"India - _ logged 19,740 new Covid-19 cases and 23,070 recoveries in the last 24 hours, & () * $ reports the ministry of health and family welfare on Saturday. With this, the country's active caseload now stands at 2,36,643, which is the lowest in 206 days. Stay with TOI for updates @ # $ from India and around the world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"India - _ logged 19,740 new Covid-19 cases and 23,070 recoveries in the last 24 hours, & () * $ reports the ministry of health and family welfare on Saturday. With this, the country's active caseload now stands at 2,36,643, which is the lowest in 206 days. Stay with TOI for updates @ # $ from India and around the world\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'In', 'wo']\n",
      "Yes there is at least one match found !\n"
     ]
    }
   ],
   "source": [
    "# How to check if the Text is starting with India \n",
    "x = re.findall(r\"\\bIn|wo\", Text)  # Checking if the string is staring with \"Ni\" or \"Ra\"\n",
    "\n",
    "# \\b is a keyword -> begining \n",
    "# r -> \"raw\" string \n",
    "print(x)\n",
    "\n",
    "if x: \n",
    "    print(\"Yes there is at least one match found !\")\n",
    "else: \n",
    "    print(\"there is no match found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n', 'd', 'i', 'a', 'l', 'o', 'g', 'g', 'e', 'd', 'n', 'e', 'w', 'o', 'v', 'i', 'd', 'c', 'a', 's', 'e', 's', 'a', 'n', 'd', 'r', 'e', 'c', 'o', 'v', 'e', 'r', 'i', 'e', 's', 'i', 'n', 't', 'h', 'e', 'l', 'a', 's', 't', 'h', 'o', 'u', 'r', 's', 'r', 'e', 'p', 'o', 'r', 't', 's', 't', 'h', 'e', 'm', 'i', 'n', 'i', 's', 't', 'r', 'y', 'o', 'f', 'h', 'e', 'a', 'l', 't', 'h', 'a', 'n', 'd', 'f', 'a', 'm', 'i', 'l', 'y', 'w', 'e', 'l', 'f', 'a', 'r', 'e', 'o', 'n', 'a', 't', 'u', 'r', 'd', 'a', 'y', 'i', 't', 'h', 't', 'h', 'i', 's', 't', 'h', 'e', 'c', 'o', 'u', 'n', 't', 'r', 'y', 's', 'a', 'c', 't', 'i', 'v', 'e', 'c', 'a', 's', 'e', 'l', 'o', 'a', 'd', 'n', 'o', 'w', 's', 't', 'a', 'n', 'd', 's', 'a', 't', 'w', 'h', 'i', 'c', 'h', 'i', 's', 't', 'h', 'e', 'l', 'o', 'w', 'e', 's', 't', 'i', 'n', 'd', 'a', 'y', 's', 't', 'a', 'y', 'w', 'i', 't', 'h', 'f', 'o', 'r', 'u', 'p', 'd', 'a', 't', 'e', 's', 'f', 'r', 'o', 'm', 'n', 'd', 'i', 'a', 'a', 'n', 'd', 'a', 'r', 'o', 'u', 'n', 'd', 't', 'h', 'e', 'w', 'o', 'r', 'l', 'd']\n"
     ]
    }
   ],
   "source": [
    "# RegEx to extract small letter words \n",
    "match = re.findall(r\"[a-z]\", Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ndia', 'logged', 'new', 'ovid', 'cases', 'and', 'recoveries', 'in', 'the', 'last', 'hours', 'reports', 'the', 'ministry', 'of', 'health', 'and', 'family', 'welfare', 'on', 'aturday', 'ith', 'this', 'the', 'country', 's', 'active', 'caseload', 'now', 'stands', 'at', 'which', 'is', 'the', 'lowest', 'in', 'days', 'tay', 'with', 'for', 'updates', 'from', 'ndia', 'and', 'around', 'the', 'world']\n"
     ]
    }
   ],
   "source": [
    "# RegEx to extract small letter words \n",
    "match = re.findall(r\"[a-z]+\", Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small and upper case both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India', 'logged', 'new', 'Covid', 'cases', 'and', 'recoveries', 'in', 'the', 'last', 'hours', 'reports', 'the', 'ministry', 'of', 'health', 'and', 'family', 'welfare', 'on', 'Saturday', 'With', 'this', 'the', 'country', 's', 'active', 'caseload', 'now', 'stands', 'at', 'which', 'is', 'the', 'lowest', 'in', 'days', 'Stay', 'with', 'TOI', 'for', 'updates', 'from', 'India', 'and', 'around', 'the', 'world']\n"
     ]
    }
   ],
   "source": [
    "match = re.findall(r\"[a-zA-Z]+\", Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19', '740', '19', '23', '070', '24', '2', '36', '643', '206']\n"
     ]
    }
   ],
   "source": [
    "# RegEx to extract only numbers \n",
    "match = re.findall(r\"[0-9]+\", Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' - _ ', ' ', ',', ' ', ' ', '-', ' ', ' ', ' ', ',', ' ', ' ', ' ', ' ', ' ', ' ', ', & () * $ ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '. ', ' ', ', ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ',', ',', ', ', ' ', ' ', ' ', ' ', ' ', ' ', '. ', ' ', ' ', ' ', ' ', ' @ # $ ', ' ', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "# Tell me everything but not the numbers and alphabets \n",
    "match = re.findall(r\"[^a-zA-Z0-9]+\", Text)\n",
    "print(match)\n",
    "\n",
    "# ^ -> everythin except the match criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '_', ',', '-', ',', ',', '&', '()', '*', '$', '.', ',', \"'\", ',', ',', ',', '.', '@', '#', '$']\n"
     ]
    }
   ],
   "source": [
    "# Also skip spaces \n",
    "match = re.findall(r\"[^a-zA-Z0-9\\s]+\", Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '_', ',', '-', ',', ',', '&', '()', '*', '$', ',', \"'\", ',', ',', ',', '@', '#', '$']\n"
     ]
    }
   ],
   "source": [
    "# Also skip dots \n",
    "match = re.findall(r\"[^a-zA-Z0-9\\s.]+\", Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '_', '-', '&', '()', '*', '$', \"'\", '@', '#', '$']\n"
     ]
    }
   ],
   "source": [
    "# Also skip commas\n",
    "match = re.findall(r\"[^a-zA-Z0-9\\s.,]+\", Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '_', '-', '&', '()', '*', '$', \"'\", '@', '#', '$']\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"[^a-zA-Z0-9\\s.,]+\"\n",
    "match = re.findall(pattern, Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India   logged 19740 new Covid19 cases and 23070 recoveries in the last 24 hours     reports the ministry of health and family welfare on Saturday With this the countrys active caseload now stands at 236643 which is the lowest in 206 days Stay with TOI for updates    from India and around the world\n"
     ]
    }
   ],
   "source": [
    "# Replace all the special characters with blank \n",
    "pattern = r\"[^a-zA-Z0-9\\s]+\"\n",
    "temp = re.sub(pattern, \"\", Text)  # Substitution to remove special characters \n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India   logged 19740 new fever cases and 23070 recoveries in the last 24 hours     reports the ministry of health and family welfare on Saturday With this the countrys active caseload now stands at 236643 which is the lowest in 206 days Stay with TOI for updates    from India and around the world\n"
     ]
    }
   ],
   "source": [
    "# Replace Covid19 with fever\n",
    "temp1 = re.sub(\"Covid19\", \"fever\", temp)\n",
    "print(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IXXXX   XXXXXX 19740 XXX XXXXX XXXXX XXX 23070 XXXXXXXXXX XX XXX XXXX 24 XXXXX     XXXXXXX XXX XXXXXXXX XX XXXXXX XXX XXXXXX XXXXXXX XX SXXXXXXX WXXX XXXX XXX XXXXXXXX XXXXXX XXXXXXXX XXX XXXXXX XX 236643 XXXXX XX XXX XXXXXX XX 206 XXXX SXXX XXXX TOI XXX XXXXXXX    XXXX IXXXX XXX XXXXXX XXX XXXXX'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A regular expression to replace all the lowercases with \"X\"\n",
    "re.sub(r\"[a-z]\", \"X\", temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(8, 10), match='va'>\n"
     ]
    }
   ],
   "source": [
    "# Check if string is ending with \"world\"\n",
    "x1 = \"Srivastava\"\n",
    "result = re.search(\"va$\", x1)  # Ending with \"va\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='Sr'>\n"
     ]
    }
   ],
   "source": [
    "# Check if string is ending with \"world\"\n",
    "x1 = \"Srivastava\"\n",
    "result = re.search(\"^Sr\", x1)  # Starting with \"Sr\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 30), match='exchajkgjgjhgjhghjghjghjghjnge'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# String starting with \"e\" ending with \"e\" and in between anything \n",
    "x1 = \"exchajkgjgjhgjhghjghjghjghjnge\"\n",
    "result = re.match(\"^e.*e$\", x1)  # \".*\" means anything in between \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match found\n"
     ]
    }
   ],
   "source": [
    "# String starting with \"e\" ending with \"e\" and in between exactly 6 characters \n",
    "x1 = \"exchange\"\n",
    "result = re.match(\"^e......e$\", x1)  # 6 \".\" means checking for 6 characters \n",
    "result\n",
    "\n",
    "if result:\n",
    "    print(\"match found\")\n",
    "else:\n",
    "    print(\"match not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shanti Nikhar 1985 ', 'Anil']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broader four operation in regular expression \n",
    "# find \n",
    "# sub \n",
    "# match \n",
    "# split \n",
    "x2 = \"Shanti Nikhar 1985 @Anil\"\n",
    "#re.split(\"\\s\", x2)  # First argumnet is spliting criteria \n",
    "#re.split(\"\\d\", x2)  # First argumnet is spliting criteria \n",
    "# Split based upon a special character \n",
    "re.split(r\"[^a-zA-Z0-9\\s]+\", x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"[^a-zA-Z0-9\\s.,]+\"\n",
    "match = re.findall(pattern, Text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_digit(text):\n",
    "    result = re.sub(r\"\\d\", \"\", text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one of the dataframe\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Reviews = pd.read_csv(\"C:\\\\JS\\\\Text_Handling_IPBA\\\\twcs\\\\twcs.csv\", nrows = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Customer_Reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the dataframe pulling only Text column \n",
    "Customer_Reviews_Text = Customer_Reviews[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Customer_Reviews_Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-96-92ff8615106b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Customer_Reviews_Text['text_lower']  = Customer_Reviews_Text[\"text\"].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# All the review in lower case letter \n",
    "Customer_Reviews_Text['text_lower']  = Customer_Reviews_Text[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \n",
       "0  @115712 i understand. i would like to assist y...  \n",
       "1      @sprintcare and how do you propose we do that  \n",
       "2  @sprintcare i have sent several private messag...  \n",
       "3  @115712 please send us a private message so th...  \n",
       "4                                 @sprintcare i did.  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Customer_Reviews_Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' India won gold medal'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To remove digits from the text \n",
    "x4 = \"2021 India won gold medal\"\n",
    "re.sub(r\"\\d\", \"\", x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom function \n",
    "def Remove_digit_IPBA(text):\n",
    "    result = re.sub(r\"\\d\", \"\", text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-84b0b1b54c9f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Customer_Reviews_Text['text_nodigits'] =  Customer_Reviews_Text['text'].apply(Remove_digit_IPBA)\n"
     ]
    }
   ],
   "source": [
    "# We are applying a custom function on all the rows of dataframe\n",
    "Customer_Reviews_Text['text_nodigits'] =  Customer_Reviews_Text['text'].apply(Remove_digit_IPBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_nodigits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>@ I understand. I would like to assist you. We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "      <td>@ Please send us a Private Message so that we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare i have sent several private messag...   \n",
       "3  @115712 please send us a private message so th...   \n",
       "4                                 @sprintcare i did.   \n",
       "\n",
       "                                       text_nodigits  \n",
       "0  @ I understand. I would like to assist you. We...  \n",
       "1      @sprintcare and how do you propose we do that  \n",
       "2  @sprintcare I have sent several private messag...  \n",
       "3  @ Please send us a Private Message so that we ...  \n",
       "4                                 @sprintcare I did.  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Customer_Reviews_Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a custom function to remove all the special characters from the text \n",
    "# Replace all the special characters with blank \n",
    "pattern = r\"[^a-zA-Z0-9\\s]+\"\n",
    "temp = re.sub(pattern, \"\", Text)  # Substitution to remove special characters \n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_special(TextValue):\n",
    "    result = re.sub(r\"[^a-zA-Z0-9\\s]+\", \"\", TextValue)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_special(T1):\n",
    "    T2 = re.sub(r\"[^a-zA-Z0-9\\s]+\", \"\", T1)\n",
    "    return T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-106-becd4a888439>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Customer_Reviews_Text['text_nospecial'] =  Customer_Reviews_Text['text'].apply(remove_all_special)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_nodigits</th>\n",
       "      <th>text_nospecial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>@ I understand. I would like to assist you. We...</td>\n",
       "      <td>115712 I understand I would like to assist you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare I have sent several private message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "      <td>@ Please send us a Private Message so that we ...</td>\n",
       "      <td>115712 Please send us a Private Message so tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare I did</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare i have sent several private messag...   \n",
       "3  @115712 please send us a private message so th...   \n",
       "4                                 @sprintcare i did.   \n",
       "\n",
       "                                       text_nodigits  \\\n",
       "0  @ I understand. I would like to assist you. We...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @ Please send us a Private Message so that we ...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                      text_nospecial  \n",
       "0  115712 I understand I would like to assist you...  \n",
       "1       sprintcare and how do you propose we do that  \n",
       "2  sprintcare I have sent several private message...  \n",
       "3  115712 Please send us a Private Message so tha...  \n",
       "4                                   sprintcare I did  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Customer_Reviews_Text['text_nospecial'] =  Customer_Reviews_Text['text'].apply(remove_all_special)\n",
    "Customer_Reviews_Text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this points my text is clean with the help of RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the time to replace text with some numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['This is Sentence One', 'This is Sentence Two', 'This is Sentence Three']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = text.CountVectorizer(input=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(matrix.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bi-gram \n",
    "cv1 = text.CountVectorizer(input=corpus, ngram_range=(2,2))\n",
    "matrix1 = cv1.fit_transform(corpus)\n",
    "pd.DataFrame(matrix1.toarray(), columns=cv1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['This is Sentence One', 'This is Sentence Two', 'This is Sentence Three']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = text.TfidfVectorizer(input=corpus, ngram_range=(1,1))\n",
    "matrix5 = tf.fit_transform(corpus)\n",
    "pd.DataFrame(matrix5.toarray(), columns=tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = text.TfidfVectorizer(input=corpus, ngram_range=(1,2))\n",
    "matrix6 = tf1.fit_transform(corpus)\n",
    "pd.DataFrame(matrix6.toarray(), columns=tf1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = ['This is Sentence One', 'Trump is Republic',  'This is Sentence Three', 'Trump is Republic and American']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = text.TfidfVectorizer(input=corpus2, ngram_range=(1,2))\n",
    "matrix7 = tf1.fit_transform(corpus2)\n",
    "#pd.DataFrame(matrix7.toarray(), columns=tf1.get_feature_names())\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(matrix7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to the root word by removing suffix or Prefix \n",
    "He was riding. \n",
    "He was taking the ride. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK -> Natural Language Tool Kit \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recommend'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem(\"recommendation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_words = [\"wait\", \"waiting\", \"waited\", \"waits\", \"awaiting\", \"crying\", \"increasing\", \"recommendation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait\n",
      "wait\n",
      "wait\n",
      "wait\n",
      "await\n",
      "cri\n",
      "increas\n",
      "recommend\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "for w in e_words:\n",
    "    rootWord = ps.stem(w)\n",
    "    print(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anparash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Dear',\n",
       " ',',\n",
       " 'It',\n",
       " 'is',\n",
       " 'great',\n",
       " 'travelling',\n",
       " 'to',\n",
       " 'different',\n",
       " 'places',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'enjoying',\n",
       " 'my',\n",
       " 'life',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fullest']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Hello Dear, It is great travelling to different places, I am enjoying my life to the fullest\"\n",
    "words = word_tokenize(sentence)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "dear\n",
      ",\n",
      "it\n",
      "is\n",
      "great\n",
      "travel\n",
      "to\n",
      "differ\n",
      "place\n",
      ",\n",
      "i\n",
      "am\n",
      "enjoy\n",
      "my\n",
      "life\n",
      "to\n",
      "the\n",
      "fullest\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "for w in words:\n",
    "    rootWord = ps.stem(w)\n",
    "    print(rootWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "text = \"Studies Studying Cries Cry\"\n",
    "words1 = nltk.word_tokenize(text)\n",
    "for w in words1:\n",
    "    rootWord = ps.stem(w)\n",
    "    print(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anparash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studies\n",
      "Studying\n",
      "Cries\n",
      "Cry\n",
      "Cry\n"
     ]
    }
   ],
   "source": [
    "# Result from Lemmatization \n",
    "# Lemmatization of NLTK doesn't work as expected \n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "WLemma = WordNetLemmatizer()\n",
    "text = \"Studies Studying Cries Cry Cry\"\n",
    "words2 = nltk.word_tokenize(text)\n",
    "for w in words2:\n",
    "    rootWord2 = WLemma.lemmatize(w)\n",
    "    print(rootWord2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "WLemma = WordNetLemmatizer()\n",
    "text = \"Studies Studying Cries Cry Cry\"\n",
    "words2 = nltk.word_tokenize(text)\n",
    "words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordNetLemmatizer.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anparash\\Anaconda3\\lib\\site-packages\\spacy\\util.py:710: UserWarning: [W095] Model 'en_core_web_sm' (3.1.0) requires spaCy >=3.1.0,<3.2.0 and is incompatible with the current version (3.0.7). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Part of Speech tagging ( POS)\n",
    "# Tag the Entities in the text \n",
    "import spacy \n",
    "from spacy import displacy\n",
    "from collections import Counter \n",
    "import en_core_web_sm  # Pre trained model \n",
    "#nlp = en_core.web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "#!pip install spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "#from spacy.lang.en import English\n",
    "\n",
    "#import spacy\n",
    "#spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization using SPACY library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cry cry lie full'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentence = \"The striped bats are hanging on their feet for best\"\n",
    "sentence = \"Crying cried Lying fullest\"\n",
    "#sentence = \"kidding dancing\"\n",
    "#sentence = \"Kidding Dancing\"\n",
    "\n",
    "# Parse the sentence using the loaded 'en' model object `nlp`\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Extract the lemma for each token and join\n",
    "\" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('European authoraties fined google a record $5.1 billion on Monday for some bad practice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('European', 'NORP'), ('a record $5.1 billion', 'MONEY'), ('Monday', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Anil has 1000 employees')\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = \"India is an amazing country. Narendra Modi is the prime minister. India is producing many businessman. Year 2021 is great for economy a deal of $2.8 billion between two japan and india\"\n",
    "#print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is an amazing country. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Narendra Modi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the prime minister. \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is producing many businessman. \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Year 2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " is great for economy a deal of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $2.8 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " between \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    japan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    india\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(doc2)), jupyter = True, style = 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER - Named Entity Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"India logged 19,740 new Covid-19 cases and 23,070 recoveries in the last 24 hours, reports the ministry of health and family welfare on Saturday. With this, the country's active caseload now stands at 2,36,643, which is the lowest in 206 days. Stay with TOI for updates from India and around the world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " logged \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    19,740\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " new Covid-19 cases and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    23,070\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " recoveries in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last 24 hours\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       ", reports the ministry of health and family welfare on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Saturday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". With this, the country's active caseload now stands at \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2,36,643\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", which is the lowest in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    206 days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". Stay with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    TOI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for updates from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and around the world</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(doc1)), jupyter = True, style = 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc1 = \"River banks in India are often flooded\"\n",
    "doc1 = \"Bank is full on money\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bank\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is full on money</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(doc1)), jupyter = True, style = 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">River bank is full on water</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#doc1 = \"River banks in India are often flooded\"\n",
    "doc1 = \"River bank is full on water\"\n",
    "displacy.render(nlp(str(doc1)), jupyter = True, style = 'ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = b\"\\xbc cup of flour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.decode(\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tweet = \"I luv my &lt;3 iphone &amp; youre awsm apple. DisplayIsAwesome, sooo happppppy  http://www.apple.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tweet.decode(\"utf8\").encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install locale\n",
    "import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.getpreferredencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(text.encode(\"utf-8\"))\n",
    "len(text.encode(\"latin-1\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
